{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <b> Definitions </b> : <br> Multithreading is the ability of a CPU to execute multiple threads concurrently. A thread is the smallest unit of a CPU's execution that can be managed independently by a scheduler. All threads in a program share the same memory space. </p>\n",
    "\n",
    "<p><b>Multithreading is useful for I/O bound tasks: </b></p>\n",
    "<li><b>Web scraping </b>: When loading multiple web pages, each request to a server can take a while to respond. Instead of waiting for each request to finish before moving on to the next one, one can use multithreading to handle multiple requests simultaneously, improving the overall speed of the scraping process.</li>\n",
    "<li><b>Server-Side Applications handling of multiple client requests: </b> Each client connection runs in its own thread, allowing the server to serve many clients concurrently.</li>\n",
    "<li><b> Database Connections and Queries</b>: When an application interacts with a database, waiting for a response from the database (especially in cases of slow queries) can block the rest of the application. With multithreading, multiple database queries can be handled concurrently, which can be especially useful for tasks like batch processing.</li>\n",
    "<li><b>Machine Learning Data Preprocessing</b>: In data science and machine learning workflows, preprocessing large datasets often involves time-consuming I/O operations (such as loading files or reading from databases). Multithreading can be used to perform data preprocessing tasks concurrently to speed up the overall workflow.  Example: A program that loads and processes large datasets from different sources, like reading data from CSV files, cleaning and transforming the data in parallel.</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multithreading Limitations:\n",
    "\n",
    "<p><b>Global Interpreter Lock</b>: <br>Is a mechanism used in CPython, which is the most widely used implementation of Python, to ensure that <b> only one thread executes Python bytecode at a time in a single process.</b>\n",
    "<br>Even if a program has multiple threads, only one thread can hold the GIL and execute Python code. Other threads will be paused until the GIL is released by the current thread. \n",
    "<br> The GIL provides <b>thread safety</b> for Python's memory management, meaning that the programmer don’t have to worry about race conditions when accessing Python objects from different threads, since only one thread can execute Python bytecode at a time.</p>\n",
    "<br>\n",
    "<p>The GIL limits true parallelism in CPU-bound tasks. Since only one thread can execute Python bytecode at any given time, Python threads don’t run truly in parallel on multiple cores when executing CPU-intensive code. This means that for multi-core processors, having multiple threads in a CPU-bound Python program might not improve performance; in fact, it can sometimes degrade performance due to the overhead of switching between threads.</p>\n",
    "<p>BUT: GIL has less impact on I/O-bound tasks (such as reading/writing files, making network requests, or interacting with databases). When a thread is performing an I/O operation, it releases the GIL, allowing other threads to run while it waits for the I/O operation to complete. This means that Python threads can still be useful for I/O-bound tasks, even though the GIL prevents full parallel execution of CPU-bound tasks. GIL maybe released when executing function written in C... (e.g. when performing numpy functionalities the GIL maybe released as part of numpy is written in C.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing\n",
    "\n",
    "<p>\n",
    "<b>Processes</b> are independent and run in separate memory spaces. Each process has its own interpreter and its own copy of the data, so they don’t share state directly (unless explicitly done via inter-process communication).\n",
    "<br> -> <b>Memory Isolation</b>\n",
    "<br> -> <b>CPU-bund tasks</b>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<li>Separate memory space: Each process in Python has its own memory and Python interpreter. This means the processes do not share data directly, unlike threads.</li>\n",
    "\n",
    "<li>Inter-process Communication (IPC): To allow processes to communicate with each other or share data, Python provides mechanisms such as Queue, Pipe, Value, and Array from the multiprocessing module.</li>\n",
    "\n",
    "<li>Process creation: Python creates new processes using the \"multiprocessing.Process\" class. Each process runs independently and can perform different tasks concurrently.</li>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
